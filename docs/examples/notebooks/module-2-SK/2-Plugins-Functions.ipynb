{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aac847a",
   "metadata": {},
   "source": [
    "# Now let's add a custom plugin and functions \n",
    "This will allow us to leverage tool/function calling with the LLM and add custom logic to our GenAI solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f77c1",
   "metadata": {},
   "source": [
    "## 1 - Create the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51d3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# Initialize the kernel\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e868829",
   "metadata": {},
   "source": [
    "## 2 - Load Azure OpenAI Endpoint Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac2a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set path to the .env file in the notebooks directory\n",
    "notebooks_dir = Path(os.path.abspath('')).parent.parent\n",
    "env_path = notebooks_dir / '.env'\n",
    "\n",
    "# Load environment variables from the notebooks/.env file\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Set up environment variables\n",
    "# You can also create a .env file with the following variables\n",
    "# AZURE_OPENAI_API_KEY=your-api-key\n",
    "# AZURE_OPENAI_ENDPOINT=your-endpoint\n",
    "\n",
    "# Check if environment variables are set\n",
    "def check_env_vars():\n",
    "    required_vars = [\"AZURE_OPENAI_API_KEY\", \"AZURE_OPENAI_ENDPOINT\"]\n",
    "    missing_vars = [var for var in required_vars if not os.environ.get(var)]\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"Warning: Missing environment variables: {', '.join(missing_vars)}\")\n",
    "        print(f\"Please create a .env file at {env_path} with these variables.\")\n",
    "        print(\"Some examples in this notebook may not work without these variables.\")\n",
    "    else:\n",
    "        print(\"All required environment variables are set!\")\n",
    "        \n",
    "        # Display part of the API key and endpoint for verification\n",
    "        api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\", \"\")\n",
    "        endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\")\n",
    "        \n",
    "        # Show only the first 5 and last 4 characters of the API key\n",
    "        if api_key:\n",
    "            masked_key = api_key[:5] + \"*\" * (len(api_key) - 9) + api_key[-4:] if len(api_key) > 9 else \"Not found\"\n",
    "            print(f\"API Key: {masked_key} (masked for security)\")\n",
    "            \n",
    "        # Show the endpoint domain\n",
    "        if endpoint:\n",
    "            print(f\"Endpoint: {endpoint}\")\n",
    "\n",
    "# Uncomment to check environment variables\n",
    "# check_env_vars()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758c209",
   "metadata": {},
   "source": [
    "## 3 - Add Chat Completion Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a4d1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added chat completion service using deployment: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# Get values from environment variables\n",
    "deployment_name = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o\")\n",
    "endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "# Add Azure OpenAI chat completion service\n",
    "chat_service = AzureChatCompletion(\n",
    "    deployment_name=deployment_name,\n",
    "    endpoint=endpoint,\n",
    "    api_key=api_key\n",
    "    # model_id=\"gpt-4\"  # Optional if deployment name matches model\n",
    ")\n",
    "\n",
    "# kernel.add_service(chat_service)\n",
    "\n",
    "print(f\"Added chat completion service using deployment: {deployment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718bcdb4",
   "metadata": {},
   "source": [
    "## 4 - Construct the Kernel, ChatHistory and get instance of the ChatCompletion Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ea2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import (\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "\n",
    "# Get the chat service from kernel\n",
    "kernel.add_service(chat_service) \n",
    "\n",
    "# Enable planning\n",
    "execution_settings = AzureChatPromptExecutionSettings()\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "        \n",
    "history = ChatHistory(system_message=\"You are a helpful assistant.\")\n",
    "history.add_user_message(\"Why is the sky blue?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca115eff",
   "metadata": {},
   "source": [
    "tweast\n",
    "\n",
    "## 5 - Add a Custom Plugin\n",
    "\n",
    "Now we'll add a custom plugin to demonstrate function calling. This involves:\n",
    "\n",
    "1. Adding the plugin directory to the Python path\n",
    "2. Importing the plugin class\n",
    "3. Registering it with the kernel\n",
    "\n",
    "The WeatherPlugin is located in the `docs/examples/plugins` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f88c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plugins'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(root_dir))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Import the WeatherPlugin\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweather_plugin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WeatherPlugin\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Create an instance of the plugin\u001b[39;00m\n\u001b[0;32m     12\u001b[0m weather_plugin \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mimport_plugin_from_object(WeatherPlugin(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeatherPlugin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plugins'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set path to the docs/examples directory to correctly find the plugins folder\n",
    "root_dir = Path(os.path.abspath('')).parent.parent\n",
    "sys.path.append(str(root_dir))\n",
    "\n",
    "# Import the WeatherPlugin\n",
    "from plugins.weather_plugin import WeatherPlugin\n",
    "\n",
    "# Create an instance of the plugin\n",
    "weather_plugin = kernel.import_plugin_from_object(WeatherPlugin(), \"WeatherPlugin\")\n",
    "\n",
    "print(\"Weather plugin imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6b6aef",
   "metadata": {},
   "source": [
    "## 6 - Test the Plugin\n",
    "\n",
    "Let's test our weather plugin by asking about the weather in different locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat history with a weather-related query\n",
    "weather_history = ChatHistory(system_message=\"You are a helpful weather assistant. Use the WeatherPlugin when asked about weather.\")\n",
    "weather_history.add_user_message(\"What's the weather like in Seattle?\")\n",
    "\n",
    "# Invoke the chat completion with our history and plugin functions available\n",
    "result = await kernel.invoke_chat(\n",
    "    chat_service,\n",
    "    weather_history,\n",
    "    execution_settings=execution_settings\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(result.value)\n",
    "\n",
    "# Add a follow-up question\n",
    "weather_history.add_user_message(\"How about Tokyo?\")\n",
    "\n",
    "# Invoke again with the updated history\n",
    "result = await kernel.invoke_chat(\n",
    "    chat_service,\n",
    "    weather_history,\n",
    "    execution_settings=execution_settings\n",
    ")\n",
    "\n",
    "# Print the updated result\n",
    "print(result.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
